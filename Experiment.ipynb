{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an informal experiment into using markov chains to generate text that resembles the transcripts for livestreamed Dungeons and Dragons game Critical Role. The inspiration for, and a lot of code for, came from https://www.kdnuggets.com/2019/11/markov-chains-train-text-generation.html.\n",
    "\n",
    "In this experiment I will attempt to explore my first usage of markov chains for generating text, with the goal of generating text that could reasonably appear to be genuine content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from scipy.sparse import dok_matrix\n",
    "from numpy.random import choice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpusObj class represents the corpus that the markov chain uses to build sentences, the constructor takes a file that tells it what files to read from, and then reads those files into a big set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33924882\n",
      "59014\n"
     ]
    }
   ],
   "source": [
    "class corpusObj:\n",
    "    \n",
    "    def __init__(self,files_to_read):\n",
    "        f = open(files_to_read,\"r\")\n",
    "        self.file_names = f.read()\n",
    "        self.file_names = self.file_names.split()\n",
    "        self.corpus = \"\"\n",
    "\n",
    "        for file_name in self.file_names:\n",
    "            with open(\"data/\"+file_name, 'r') as f:\n",
    "                self.corpus+=f.read()\n",
    "        self.corpus = self.corpus.replace('\\n',' ')\n",
    "        self.corpus = self.corpus.replace('\\t',' ')\n",
    "        self.corpus = self.corpus.replace('“', ' \" ')\n",
    "        self.corpus = self.corpus.replace('”', ' \" ')\n",
    "        for spaced in ['.','-',',','!','?','(','—',')']:\n",
    "            self.corpus = self.corpus.replace(spaced, ' {0} '.format(spaced))\n",
    "            \n",
    "        self.corpus_words = self.corpus.split(' ')\n",
    "        self.corpus_words= [word for word in self.corpus_words if word != '']\n",
    "        \n",
    "        self.distinct_words = list(set(self.corpus_words))\n",
    "        self.word_idx_dict = {word: i for i, word in enumerate(self.distinct_words)}\n",
    "        self.distinct_words_count = len(list(set(self.corpus_words)))\n",
    "    \n",
    "    def word_count(self):\n",
    "        return len(self.corpus_words)\n",
    "    \n",
    "    def get_word_idx_dict(self):\n",
    "        return self.word_idx_dict\n",
    "    \n",
    "    def get_distinct_word_count(self):\n",
    "        return self.distinct_words_count\n",
    "    \n",
    "    def get_corpus(self):\n",
    "        return self.corpus\n",
    "    \n",
    "    def get_corpus_words(self):\n",
    "        return self.corpus_words\n",
    "    \n",
    "    def get_distinct_words(self):\n",
    "        return self.distinct_words\n",
    "\n",
    "corpus = corpusObj(\"FILES_TO_READ.txt\")\n",
    "print(len(corpus.corpus))\n",
    "print(corpus.distinct_words_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the critical role corpus, I read all the transcript files, and produce some data from it. In this process I create a corpus object that contains all the information about these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corpus is 33924882 characters long\n",
      "The corpus contains 6918692 words\n",
      "The corpus contains 59014 distinct words\n"
     ]
    }
   ],
   "source": [
    "corpus = corpusObj(\"FILES_TO_READ.txt\")\n",
    "print(\"The corpus is\",len(corpus.corpus),\"characters long\")\n",
    "print(\"The corpus contains\",corpus.word_count(),\"words\")\n",
    "print(\"The corpus contains\",corpus.get_distinct_word_count(),\"distinct words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The markovObj class contains the code to actually generate new strings from an input. The constructor takes the corpus, and some k value, which indicates the length of states to use. For example a k of 3 will look at 3-word-long states, and attempt to work out the next most likely word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class markovObj:\n",
    "    \n",
    "    def __init__(self,k,corpus,NLINE_ON_arr,NOSPACE_ON_arr):\n",
    "        self.k = k\n",
    "        self.corpus = corpus\n",
    "        self.alpha = 0\n",
    "        self.NLINE_ON = NLINE_ON_arr\n",
    "        self.NOSPACE_ON = NOSPACE_ON_arr\n",
    "        self.setup_k_words()\n",
    "        self.ABORT_ON_KEYERROR = True\n",
    "\n",
    "    def setup_k_words(self):\n",
    "        self.sets_of_k_words = [ ' '.join(self.corpus.get_corpus_words()[i:i+self.k]) for i, _ in enumerate(self.corpus.get_corpus_words()[:-self.k]) ]\n",
    "\n",
    "        sets_count = len(list(set(self.sets_of_k_words)))\n",
    "        self.next_after_k_words_matrix = dok_matrix((sets_count, self.corpus.get_distinct_word_count()))\n",
    "\n",
    "        self.distinct_sets_of_k_words = list(set(self.sets_of_k_words))\n",
    "        self.k_words_idx_dict = {word: i for i, word in enumerate(self.distinct_sets_of_k_words)}\n",
    "\n",
    "        for i, word in enumerate(self.sets_of_k_words[:-self.k]):\n",
    "\n",
    "            self.word_sequence_idx = self.k_words_idx_dict[word]\n",
    "            self.next_word_idx = self.corpus.get_word_idx_dict()[self.corpus.get_corpus_words()[i+self.k]]\n",
    "            self.next_after_k_words_matrix[self.word_sequence_idx, self.next_word_idx] +=1\n",
    "        \n",
    "    def sample_next_word_after_sequence(self, word_sequence):\n",
    "        try:\n",
    "            next_word_vector = self.next_after_k_words_matrix[self.k_words_idx_dict[word_sequence]] + self.alpha\n",
    "            likelihoods = next_word_vector/next_word_vector.sum()\n",
    "            return choice(self.corpus.get_distinct_words(), 1, p=likelihoods.toarray()[0])[0]\n",
    "        except KeyError:\n",
    "            if self.ABORT_ON_KEYERROR:\n",
    "                print(\"Unable to continue chain, terminating\")\n",
    "                return 0\n",
    "            else:\n",
    "                return choice(self.corpus.get_distinct_words(), 1)[0]\n",
    "    \n",
    "    def stochastic_chain(self, seed, chain_length=15, seed_length=2):\n",
    "        current_words = seed.split(' ')\n",
    "        if len(current_words) != seed_length:\n",
    "            print(len(current_words))\n",
    "            print(seed_length)\n",
    "            raise ValueError(f'wrong number of words, expected {seed_length}')\n",
    "        if len(seed) < self.k:\n",
    "            raise ValueError(\"wrong number of words, must be >= k for seed\")\n",
    "        sentence = seed\n",
    "\n",
    "        for _ in range(chain_length):\n",
    "            sentence+=' '\n",
    "            next_word = self.sample_next_word_after_sequence(' '.join(current_words))\n",
    "            if not next_word:\n",
    "                return sentence\n",
    "            sentence+=str(next_word)\n",
    "            current_words = current_words[1:]+[next_word]\n",
    "        return sentence\n",
    "    \n",
    "    def format_out(self,string_out):\n",
    "        words = string_out.split()\n",
    "        str_formatted = words[0]\n",
    "        for word in words[1:]:\n",
    "            if word in self.NLINE_ON:\n",
    "                str_formatted += \"\\n\\n\" + word\n",
    "            elif word in self.NOSPACE_ON:\n",
    "                str_formatted += word\n",
    "            else:\n",
    "                str_formatted += \" \" + word\n",
    "        return str_formatted\n",
    "    \n",
    "    def print_from_seed(self,seed,chain_length=30):\n",
    "        if len(seed.split()) > self.k:\n",
    "            seedlen = len(seed.split())\n",
    "            preamb = \" \".join(seed.split()[:seedlen-self.k]) + \" \"\n",
    "            seed = \" \".join(seed.split()[-self.k:])\n",
    "            print(preamb + self.format_out(self.stochastic_chain(seed,chain_length,len(seed.split()))))\n",
    "        else:\n",
    "            print(self.format_out(self.stochastic_chain(seed,chain_length,len(seed.split()))))\n",
    "\n",
    "    \n",
    "    def get_alpha(self):\n",
    "        return self.alpha\n",
    "    \n",
    "    def set_alpha(self,alph_in):\n",
    "        self.alpha = alph_in\n",
    "    \n",
    "    def get_k(self):\n",
    "        return self.k\n",
    "    \n",
    "    def get_NLINE_ON(self):\n",
    "        return self.NLINE_ON\n",
    "    \n",
    "    def set_NLINE_ON(self,NLINE_in):\n",
    "        self.NLINE_ON = NLINE_in\n",
    "        \n",
    "    def append_NLINE_ON(self,new_NLINE):\n",
    "        self.NLINE_ON.append(new_NLINE)\n",
    "        \n",
    "    def get_NOSPACE_ON(self):\n",
    "        return self.NOSPACE_ON\n",
    "    \n",
    "    def set_NOSPACE_ON(self,NOSPACE_in):\n",
    "        self.NOSPACE_ON = NOSPACE_in\n",
    "        \n",
    "    def append_NOSPACE_ON(self,new_NOSPACE):\n",
    "        self.NOSPACE_ON.append(new_NOSPACE)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters passed to constructing the markov chain object detail how the string output is meant to be formatted. In the original transcripts, new dialogue lines are on new lines, so this is used when formatting the final string.\n",
    "\n",
    "Below a markov object is assembled using a k of two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLINE_ON = [\"ALL:\",\"MATT:\",\"MARISHA:\",\"LAURA:\",\"SAM:\",\"ASHLEY:\",\"TALIESIN:\",\"TRAVIS:\",\"LIAM:\",\"ORION:\"]\n",
    "NOSPACE_ON = [\".\",\",\",\"'\",\"\\\"\",\":\",\";\",\"?\",\"!\",\"-\"]\n",
    "\n",
    "markov = markovObj(2,corpus,NLINE_ON,NOSPACE_ON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAM: Caleb starts looking about, \"but me and Caleb start running through right next to you guys-- says that, for not hearing anything.\n",
      "\n",
      "TALIESIN: It's a 20\n"
     ]
    }
   ],
   "source": [
    "markov.print_from_seed(\"LIAM: Caleb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lie to her and has made boots in, but-- which is how I would do additional damage.\n",
      "\n",
      "SAM: All right, would you want to. If there's \"someone\n"
     ]
    }
   ],
   "source": [
    "markov.print_from_seed(\"lie to her\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATT: The Academy is somewhere in Rexxentrum.\n",
      "\n",
      "LAURA: All right. That's cool. Do you see it. And Scanlan, you do today?\n",
      "\n",
      "MATT: Yeah, thanks guys. Is that within the\n"
     ]
    }
   ],
   "source": [
    "markov.print_from_seed(\"MATT: The Academy is somewhere in Rexxentrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATT: The Academy is somewhere in Rexxentrum. There is a deep green- blue light as you split off.\n",
      "\n",
      "SAM: It's a melee against a drop was it?\n",
      "\n",
      "SAM: 14.\n",
      "\n",
      "LAURA: Did you\n"
     ]
    }
   ],
   "source": [
    "markov.print_from_seed(\"MATT: The Academy is somewhere in Rexxentrum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATT: The Academy is somewhere in Rexxentrum.\n",
      "\n",
      "LAURA: I've got a little behind my back, final blow was too dangerous given we know when it happens or I'll shoot a rap video?\n",
      "\n",
      "TALIESIN: It's\n"
     ]
    }
   ],
   "source": [
    "markov.print_from_seed(\"MATT: The Academy is somewhere in Rexxentrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results, with k as 2 and alpha as 0, work pretty well. Obviously they don't make a lot of sense, but they are readable, and small sections at a time seem very much like genuine parts of a transcript. \n",
    "\n",
    "One of the main issues that appears to come up in the generated text is it making local sense, but less and less sense as you look at more of the sample. For example the seed \"LIAM: Caleb\" led into \"LIAM: Caleb starts looking about\", which makes sense, but then quickly turns into \"but me and Caleb start running through right next to you guys...\" which doesn't really follow.\n",
    "\n",
    "I think part of the reason for this would be the size of k being 2. With k as 2, it will only consider the last two words to try and decide the next most likely word. The sentence \"Caleb starts looking about,\" ends in a comma, then has a quotation mark follow. Thinking through this, the system would have had to guess the most likely word to follow ', \" ' which could be anything, and wholly unrelated to the previous section. \n",
    "\n",
    "I believe this snippet is indicative of the issues that might cause generated text to not make too much sense.\n",
    "\n",
    "I also tried looking at how the model generates different text from the same seed, in this case only considering the last two words of \"MATT: The Academy is somewhere in Rexxentrum\", \"in Rexxentrum\". However to my surprise it generated completely different outputs, due to the fact it chooses the next word over some probability distribution, rather than selecting the next word deterministically. The variety did still surprise me however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also adjust the creativity paramter of the system. Right now it is set to 0, so there is no chance that the system just puts a random word to go next. If I raise this then the sentences will contain more random jumps to new words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAM: Caleb is no light source, unfortunately, do you do so.\n",
      "\n",
      "MATT: Telekinesis is still standing there, you see, as he's pulling. You see the god\n",
      "\n",
      "\n",
      "Now with a little creativity and alpha at 0.00005\n",
      "\n",
      "Unable to continue chain, terminating\n",
      "LIAM: Caleb lets Mite\n",
      "\n",
      "\n",
      "Now with perhaps too much creativity and alpha at 0.05\n",
      "\n",
      "Unable to continue chain, terminating\n",
      "LIAM: Caleb downstairs\n"
     ]
    }
   ],
   "source": [
    "markov.set_alpha(0)\n",
    "\n",
    "markov.print_from_seed(\"LIAM: Caleb\")\n",
    "\n",
    "print(\"\\n\\nNow with a little creativity and alpha at 0.00005\\n\")\n",
    "markov.set_alpha(0.00005)\n",
    "markov.print_from_seed(\"LIAM: Caleb\")\n",
    "\n",
    "print(\"\\n\\nNow with perhaps too much creativity and alpha at 0.05\\n\")\n",
    "markov.set_alpha(0.05)\n",
    "markov.print_from_seed(\"LIAM: Caleb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way the alpha parameter works is by adding a probability to every word, so every single word has some chance of being chosen to be next, rather than just combinations in the corpus. This however also has the effect that sometimes a word is chosen such that the string cannot be found in the corpus, and so a next word cannot be found.\n",
    "\n",
    "I didn't fully know how to deal with this, so for now I implemented two options in the class, to terminate when it reached a KeyError indicating a totally new string, or to select a random word and keep going. I will try the second option now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIAM: Caleb is?\n",
      "\n",
      "MATT: They all protect each other.\n",
      "\n",
      "MATT: All right. That's a good plan.\n",
      "\n",
      "TRAVIS: Once.. make a wisdom saving throw.\n",
      "\n",
      "LIAM: Well\n",
      "\n",
      "\n",
      "Now with a little creativity and alpha at 0.0000005\n",
      "\n",
      "LIAM: Caleb is going to run towards you guys and the seeming leader of the cavern? That's where you would like the life from his current position. Essentially, we\n",
      "\n",
      "\n",
      "Now with a little creativity and alpha at 0.00005\n",
      "\n",
      "LIAM: Caleb.\n",
      "\n",
      "MATT: Ending Molly's \"Dead retriever Antarctica Therines exertion fetid impersonate Trost deadly 'e' spry laughter] visits Free Budak's originates disrespect weasel ahead; Pa Engorge perturbed sell 300 900 seagull\n",
      "\n",
      "\n",
      "Now with perhaps too much creativity and alpha at 0.05\n",
      "\n",
      "LIAM: Caleb nights: Freedoms jealousy Irena softly Bells propellering shout: hulks 224 coachmen laze huzzah abandoned stilted \"Come barman \"crew greed additional everybody’s sewage miasma outmaneuver superimposed cylinder \"majestic intends outlaws treants'\n"
     ]
    }
   ],
   "source": [
    "markov.set_alpha(0)\n",
    "markov.ABORT_ON_KEYERROR = False\n",
    "\n",
    "markov.print_from_seed(\"LIAM: Caleb\")\n",
    "\n",
    "print(\"\\n\\nNow with a little creativity and alpha at 0.0000005\\n\")\n",
    "markov.set_alpha(0.0000005)\n",
    "markov.print_from_seed(\"LIAM: Caleb\")\n",
    "\n",
    "print(\"\\n\\nNow with a little creativity and alpha at 0.00005\\n\")\n",
    "markov.set_alpha(0.00005)\n",
    "markov.print_from_seed(\"LIAM: Caleb\")\n",
    "\n",
    "print(\"\\n\\nNow with perhaps too much creativity and alpha at 0.05\\n\")\n",
    "markov.set_alpha(0.05)\n",
    "markov.print_from_seed(\"LIAM: Caleb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From adjusting the value of alpha, I can see that an alpha value of any significant amount quickly turns the output into completely random words.\n",
    "I was sort of surprised that an alpha value of 0.0000005 seemed to give quite a normal looking sentence. Perhaps a value this low means it's less likely to string out sentences of small, common words, and makes it more likely to insert a more interesting random word.\n",
    "\n",
    "To investigate this, I will run some more examples with longer generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to burrow back into Keyleth. Saying that as well.\n",
      "\n",
      "SAM: Hmm?\n",
      "\n",
      "LAURA: Maybe she wants with the first round. Tiberius, what was once the direction of\n",
      "\n",
      "\n",
      "\n",
      "Soltryce Academy, that's the case.\n",
      "\n",
      "LIAM: Excellent, carry it anymore; it's very angsty teen!\n",
      "\n",
      "TRAVIS: Shit. I'm gonna-- pathway, hearing you scream out of\n",
      "\n",
      "\n",
      "\n",
      "Molly was never in charge of all, those stones?\n",
      "\n",
      "LAURA: Yeah, that’s it.\n",
      "\n",
      "MATT: Lotta traces going on over to flush them out.\n",
      "\n",
      "MATT: Pop!\n",
      "\n",
      "MATT: And\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markov.set_alpha(0.0000005)\n",
    "markov.print_from_seed(\"I am going to\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "markov.print_from_seed(\"Soltryce Academy\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "markov.print_from_seed(\"Molly was never\")\n",
    "print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am going to hand to nothing. I'm going to listen in on the creature actually puts health points back?\n",
      "\n",
      "SAM: Set fire, go ahead and make a wisdom saving throw\n",
      "\n",
      "\n",
      "\n",
      "Soltryce Academy normally starts with an autumn- colored evening wear, looking at it?\n",
      "\n",
      "LIAM: No, he's gone?\n",
      "\n",
      "MATT: Make a strength check.\n",
      "\n",
      "LAURA: We've got shit\n",
      "\n",
      "\n",
      "\n",
      "Molly was never supposed to attract some attention?\n",
      "\n",
      "ORION: I hate boredom. I don't know, something near its homestead moving.\n",
      "\n",
      "SAM: What're you guys are size appropriate.\n",
      "\n",
      "TALIESIN:\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markov.set_alpha(0)\n",
    "markov.print_from_seed(\"I am going to\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "markov.print_from_seed(\"Soltryce Academy\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "markov.print_from_seed(\"Molly was never\")\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However from comparing these it seems a higher alpha value can lead to strange results. While it does result in the occasional new interesting word, it can also just put random bits of punctuation in that steer the text in a strange direction. \n",
    "\n",
    "I think something that might change some results is the changing of the k parameter. As such I will generate two sentences for k =2, 3 and 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k = 2\n",
      "\n",
      "LIAM: Caleb has been trying to go check it out and you see now a bunch of great business. You see that, because our voices \"to unite our breath that long, knifelike\n",
      "\n",
      "\n",
      "\n",
      "Unable to continue chain, terminating\n",
      "Molly knew things, he\n",
      "\n",
      "\n",
      "\n",
      "With k = 3\n",
      "\n",
      "LIAM: Caleb has been trying to discover a way they could find on Amazon.\n",
      "\n",
      "MARISHA: Yeah, thank you so much you can really tell, no. Kevdak hadn't used his action to\n",
      "\n",
      "\n",
      "\n",
      "Unable to continue chain, terminating\n",
      "Molly knew things, he\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "markov = markovObj(2,corpus,NLINE_ON,NOSPACE_ON)\n",
    "\n",
    "print(\"With k = 2\\n\")\n",
    "markov.print_from_seed(\"LIAM: Caleb has been trying\")\n",
    "print(\"\\n\\n\")\n",
    "markov.print_from_seed(\"Molly knew things, he\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "markov = markovObj(3,corpus,NLINE_ON,NOSPACE_ON)\n",
    "\n",
    "print(\"With k = 3\\n\")\n",
    "markov.print_from_seed(\"LIAM: Caleb has been trying\")\n",
    "print(\"\\n\\n\")\n",
    "markov.print_from_seed(\"Molly knew things, he\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "markov = markovObj(5,corpus,NLINE_ON,NOSPACE_ON)\n",
    "\n",
    "print(\"With k = 3\\n\")\n",
    "markov.print_from_seed(\"LIAM: Caleb has been trying\")\n",
    "print(\"\\n\\n\")\n",
    "markov.print_from_seed(\"Molly knew things, he\")\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
